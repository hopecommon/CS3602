### Environment variables for reproducible runs

# Hugging Face caches
HF_HOME=/path/to/.cache/huggingface
HF_DATASETS_CACHE=$HF_HOME/datasets
HF_HUB_OFFLINE=1
TRANSFORMERS_OFFLINE=1

MODEL_NAME=EleutherAI/pythia-2.8b

# Override Python interpreter (optional)
PYTHON_BIN=kvpress/.venv/bin/python

# Dataset-specific defaults (used by run_kvpress_streaming_decode.sh)
DATASET_NAME=wikitext
DATASET_CONFIG=wikitext-103-v1
SPLIT=test
TEXT_COLUMN=text

# Experiment configs
N_SINK=4
WINDOW_SIZE=1024

# Dataset-specific sampling controls
WIKITEXT_MAX_SAMPLES=128
PG19_MAX_SAMPLES=1

# Dataset-specific token windows used by run_comprehensive_comparisons.sh
WIKITEXT_MAX_TOKENS=4096
PG19_20K_MAX_TOKENS=20000
PG19_MAX_TOKENS=20000

# PG19 sample selector (optional)
PG19_SAMPLE_LENGTH=20000
# Alternatively you can pin to an explicit generated file:
# PG19_SAMPLE_FILE=/path/to/data/pg19/long_context_20000.json

# WikiText sample selector
WIKITEXT_SAMPLE_LENGTH=4096
# WIKITEXT_SAMPLE_FILE=/path/to/data/wikitext/long_context_4096.json

# Decode-loop controls (run_everything.sh / experiments rely on these)
MAX_LENGTH=2048
STRIDE=1024
