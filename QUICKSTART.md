# å¿«é€Ÿå¼€å§‹æŒ‡å—

æœ¬æ–‡æ¡£æä¾›å¿«é€Ÿè¿è¡Œé¡¹ç›®çš„å®Œæ•´æ­¥éª¤è¯´æ˜,åŒ…æ‹¬ç¯å¢ƒé…ç½®ã€å¿«é€Ÿæµ‹è¯•ã€è¿è¡Œå®éªŒå’Œæ•…éšœæ’é™¤ã€‚

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [å¿«é€Ÿæµ‹è¯•](#å¿«é€Ÿæµ‹è¯•)
- [è¿è¡Œå®éªŒ](#è¿è¡Œå®éªŒ)
- [ä½¿ç”¨ä¸€é”®è„šæœ¬](#ä½¿ç”¨ä¸€é”®è„šæœ¬)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## ğŸ”§ ç¯å¢ƒé…ç½®

### æ¨èæ–¹æ¡ˆï¼šå¤ç”¨ kvpress ç¯å¢ƒ

**ä¼˜åŠ¿**:
- âœ… æ— éœ€é¢å¤–å®‰è£… - kvpress å·²åŒ…å«æ‰€æœ‰å¿…éœ€ä¾èµ–
- âœ… ç‰ˆæœ¬å…¼å®¹ - é¿å…ä¾èµ–å†²çª
- âœ… èŠ‚çœæ—¶é—´ - ç«‹å³å¼€å§‹å®éªŒ
- âœ… ç¯å¢ƒä¸€è‡´ - ä¸ kvpress åŸºçº¿ä½¿ç”¨ç›¸åŒç¯å¢ƒ

### å¿«é€Ÿé…ç½®æ­¥éª¤

```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd /data2/jflin/CS3602

# 2. æ¿€æ´» kvpress çš„è™šæ‹Ÿç¯å¢ƒ
cd kvpress
source .venv/bin/activate
cd ..

# 3. é…ç½® Hugging Face ç¼“å­˜
mkdir -p .cache/huggingface
export HF_HOME=$PWD/.cache/huggingface

# 4. (å¯é€‰) ä½¿ç”¨é•œåƒåŠ é€Ÿä¸‹è½½ (å›½å†…ç”¨æˆ·)
export HF_ENDPOINT=https://hf-mirror.com
```

### å¦‚æœ .venv ä¸å­˜åœ¨

é¦–æ¬¡ä½¿ç”¨éœ€è¦åˆ›å»º kvpress ç¯å¢ƒ:

```bash
cd kvpress
UV_CACHE_DIR=$PWD/.cache/uv uv sync --all-groups
UV_CACHE_DIR=$PWD/.cache/uv uv sync --extra eval
source .venv/bin/activate
cd ..
```

**è¯´æ˜**: 
- `uv sync --all-groups` å®‰è£…æ‰€æœ‰ä¾èµ–ç»„
- `uv sync --extra eval` å®‰è£…è¯„ä¼°ç›¸å…³ä¾èµ–

### éªŒè¯ç¯å¢ƒ

```bash
# æµ‹è¯• Python æ¨¡å—
python -c "
import torch
import transformers
from datasets import load_dataset
print(f'âœ“ PyTorch: {torch.__version__}')
print(f'âœ“ Transformers: {transformers.__version__}')
print(f'âœ“ CUDA available: {torch.cuda.is_available()}')
"

# æµ‹è¯•é¡¹ç›®æ¨¡å—
python -c "
from streaming_llm import StreamingLLMWrapper
print('âœ“ StreamingLLM æ¨¡å—åŠ è½½æˆåŠŸ')
"
```

### kvpress ç¯å¢ƒåŒ…å«çš„ä¾èµ–

æ ¸å¿ƒä¾èµ–:
- `torch>=2.3.1` - PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
- `transformers>=4.56` - Hugging Face Transformers
- `datasets>=2.21.0` - æ•°æ®é›†åŠ è½½
- `accelerate>=1.0.0` - æ¨¡å‹åŠ é€Ÿ
- `numpy>=2.0.0` - æ•°å€¼è®¡ç®—

è¯„ä¼°ä¾èµ–:
- `pandas>=2.2.2` - æ•°æ®å¤„ç†
- `tqdm>=4.66.4` - è¿›åº¦æ¡
- `scipy>=1.13.1` - ç§‘å­¦è®¡ç®—
- `matplotlib` - å¯è§†åŒ–

---

## âš¡ å¿«é€Ÿæµ‹è¯•

### æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½

```bash
# æµ‹è¯• StreamingLLM åŸºæœ¬åŠŸèƒ½ (çº¦ 1 åˆ†é’Ÿ)
python experiments/test_streaming_llm.py
```

å¦‚æœæµ‹è¯•é€šè¿‡,ä½ ä¼šçœ‹åˆ°:
```
âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡!
```

### è¿è¡Œå•ä¸ªå®éªŒ

```bash
# WikiText-103 è¯„ä¼° (çº¦ 2-3 åˆ†é’Ÿ)
python experiments/eval_streaming_llm.py \
  --dataset-name wikitext \
  --dataset-config wikitext-103-v1 \
  --max-samples 64 \
  --max-eval-tokens 4096 \
  --n-sink 4 \
  --window-size 1024 \
  --output results/streaming_llm/wikitext_result.json
```

### æŸ¥çœ‹ç»“æœ

```bash
# æŸ¥çœ‹ JSON ç»“æœ
cat results/streaming_llm/wikitext_result.json

# æˆ–ä½¿ç”¨ jq æ ¼å¼åŒ–
cat results/streaming_llm/wikitext_result.json | jq .
```

---

## ğŸ“Š è¿è¡Œå®éªŒ

### æ–¹å¼ 1: ä½¿ç”¨ä¸€é”®è„šæœ¬ (æ¨è)

```bash
# ç»™è„šæœ¬æ·»åŠ æ‰§è¡Œæƒé™ (é¦–æ¬¡è¿è¡Œ)
chmod +x run_everything.sh run_decoding_latency.sh

# è¿è¡Œæ‰€æœ‰ä¸»å®éªŒ (çº¦ 25 åˆ†é’Ÿ)
./run_everything.sh

# è¿è¡Œ decoding latency å®éªŒ (çº¦ 20 åˆ†é’Ÿ)
./run_decoding_latency.sh
```

### æ–¹å¼ 2: ä½¿ç”¨ Python è„šæœ¬

```bash
# è¿è¡Œæ‰€æœ‰å®éªŒå¹¶è‡ªåŠ¨ç”Ÿæˆå›¾è¡¨
python experiments/run_all_experiments.py
```

### æ–¹å¼ 3: å•ç‹¬è¿è¡Œå®éªŒ

#### Baseline å®éªŒ

```bash
# WikiText-103 Baseline
python experiments/eval_streaming_llm.py \
  --dataset-name wikitext \
  --dataset-config wikitext-103-v1 \
  --max-samples 64 \
  --max-eval-tokens 4096 \
  --n-sink 0 \
  --window-size 999999 \
  --output results/streaming_llm/wikitext_baseline.json

# PG19 Baseline
python experiments/eval_streaming_llm.py \
  --dataset-name pg19 \
  --max-samples 1 \
  --max-eval-tokens 4096 \
  --n-sink 0 \
  --window-size 999999 \
  --trust-remote-code \
  --output results/streaming_llm/pg19_baseline.json
```

#### StreamingLLM å®éªŒ

```bash
# WikiText-103 StreamingLLM
python experiments/eval_streaming_llm.py \
  --dataset-name wikitext \
  --dataset-config wikitext-103-v1 \
  --max-samples 64 \
  --max-eval-tokens 4096 \
  --n-sink 4 \
  --window-size 1024 \
  --output results/streaming_llm/wikitext_result.json

# PG19 StreamingLLM
python experiments/eval_streaming_llm.py \
  --dataset-name pg19 \
  --max-samples 1 \
  --max-eval-tokens 4096 \
  --n-sink 4 \
  --window-size 1024 \
  --trust-remote-code \
  --output results/streaming_llm/pg19_result.json
```

#### æ¶ˆèå®éªŒ

```bash
# Window Size æ¶ˆè
python experiments/ablation_study.py \
  --ablation-type window_size \
  --output results/streaming_llm/ablation_window_size.json

# N_sink æ¶ˆè
python experiments/ablation_study.py \
  --ablation-type n_sink \
  --output results/streaming_llm/ablation_n_sink.json
```

#### å¯¹æ¯”å®éªŒ (ä¸ kvpress å¯¹æ¯”)

```bash
# WikiText å¯¹æ¯”
python experiments/run_comparison.py --dataset wikitext

# PG19 å¯¹æ¯”
python experiments/run_comparison.py --dataset pg19

# ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
python experiments/plot_comparison.py
```

### ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨

```bash
# ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
python experiments/generate_final_figures.py

# æˆ–å•ç‹¬ç”Ÿæˆ
python experiments/plot_results.py
python experiments/plot_comparison.py
```

---

## ğŸš€ ä½¿ç”¨ä¸€é”®è„šæœ¬

### run_everything.sh - ä¸»å®éªŒè„šæœ¬

**åŒ…å«å†…å®¹**:
- âœ… Baseline å®éªŒ (WikiText-103 & PG19)
- âœ… æˆ‘ä»¬çš„ StreamingLLM å®éªŒ
- âœ… kvpress å®˜æ–¹åº“å¯¹æ¯”å®éªŒ
- âœ… æ¶ˆèå®éªŒ (Window Size & N_sink)
- âœ… è‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
- âœ… è¯¦ç»†çš„æ—¥å¿—å’Œæ€»ç»“æŠ¥å‘Š

**è¾“å‡ºæ–‡ä»¶**:
- å®éªŒç»“æœ: `results/streaming_llm/`, `results/kvpress/`
- å¯è§†åŒ–å›¾è¡¨: `results/figures/`
- æ—¥å¿—æ–‡ä»¶: `results/experiment_log_*.txt`
- æ€»ç»“æŠ¥å‘Š: `results/experiment_summary_*.txt`

### run_decoding_latency.sh - Decoding Latency å®éªŒ

**åŠŸèƒ½**:
- æµ‹é‡ per-token decoding latency
- å¯¹æ¯” Baseline å’Œ StreamingLLM
- å¤šç§ cache size é…ç½® (512, 1024, 2048, 4096)
- é•¿åºåˆ—æµ‹è¯• (5000 tokens)
- ä¸åŒ n_sink é…ç½®æµ‹è¯•

**ç‰¹ç‚¹**:
- GPU warmup (200 tokens)
- å¤šæ¬¡è¿è¡Œå–å¹³å‡ (3 runs)
- ç²¾ç¡®è®¡æ—¶ (torch.cuda.synchronize)
- åªç»Ÿè®¡ cache å¡«æ»¡åçš„ tokens

**è¾“å‡ºæ–‡ä»¶**:
- ç»“æœæ–‡ä»¶: `results/decoding_latency_*.json`
- æ—¥å¿—æ–‡ä»¶: `results/decoding_latency_log_*.txt`
- æ€»ç»“æŠ¥å‘Š: `results/decoding_latency_summary_*.txt`

### æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨

```bash
# å›¾è¡¨ä¿å­˜åœ¨ results/figures/ ç›®å½•
ls results/figures/

# è¾“å‡º:
# - main_comparison.png          # ä¸»å®éªŒå¯¹æ¯” (PPL, åŠ é€Ÿæ¯”, å‹ç¼©æ¯”, Runtime)
# - ablation_window_size.png     # Window Size æ¶ˆè
# - ablation_n_sink.png          # N_sink æ¶ˆè
# - results_summary.png          # ç»“æœæ€»ç»“è¡¨æ ¼
# - implementation_comparison.png # å®ç°å¯¹æ¯”
# - comparison_metrics_table.png # å¯¹æ¯”æŒ‡æ ‡è¡¨æ ¼
```

---

## ğŸ” å®éªŒè„šæœ¬å‚æ•°è¯´æ˜

### eval_streaming_llm.py

ä¸»è¯„ä¼°è„šæœ¬,æ”¯æŒå¤šç§é…ç½®:

**å‚æ•°è¯´æ˜**:
- `--model-name`: æ¨¡å‹åç§° (é»˜è®¤: EleutherAI/pythia-70m)
- `--dataset-name`: æ•°æ®é›†åç§° (wikitext, pg19)
- `--dataset-config`: æ•°æ®é›†é…ç½® (å¦‚ wikitext-103-v1)
- `--max-samples`: æœ€å¤§æ ·æœ¬æ•°
- `--max-eval-tokens`: æœ€å¤§è¯„ä¼° token æ•°
- `--n-sink`: Sink token æ•°é‡ (é»˜è®¤: 4)
- `--window-size`: æ»‘åŠ¨çª—å£å¤§å° (é»˜è®¤: 1024)
- `--output`: è¾“å‡ºæ–‡ä»¶è·¯å¾„
- `--trust-remote-code`: ä¿¡ä»»è¿œç¨‹ä»£ç  (PG19 éœ€è¦)

### ablation_study.py

æ¶ˆèå®éªŒè„šæœ¬:

**å‚æ•°è¯´æ˜**:
- `--ablation-type`: æ¶ˆèç±»å‹ (window_size, n_sink)
- `--output`: è¾“å‡ºæ–‡ä»¶è·¯å¾„

### run_comparison.py

å¯¹æ¯”å®éªŒè„šæœ¬ (æˆ‘ä»¬çš„å®ç° vs kvpress):

**å‚æ•°è¯´æ˜**:
- `--dataset`: æ•°æ®é›†é€‰æ‹© (wikitext, pg19)
- `--n-sink`: Sink token æ•°é‡
- `--window-size`: æ»‘åŠ¨çª—å£å¤§å°
- `--max-samples`: æœ€å¤§æ ·æœ¬æ•°
- `--max-eval-tokens`: æœ€å¤§è¯„ä¼° token æ•°

---

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜ 1: ç¯å¢ƒæœªæ¿€æ´»

**é”™è¯¯ä¿¡æ¯**:
```
ModuleNotFoundError: No module named 'transformers'
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿æ¿€æ´»äº† kvpress çš„è™šæ‹Ÿç¯å¢ƒ
cd kvpress
source .venv/bin/activate
cd ..
```

### é—®é¢˜ 2: CUDA å†…å­˜ä¸è¶³

**é”™è¯¯ä¿¡æ¯**:
```
RuntimeError: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆ**:
- å‡å°‘ `--max-eval-tokens` (å¦‚ 4096 â†’ 2048)
- å‡å°‘ `--max-samples` (å¦‚ 64 â†’ 32)
- ä½¿ç”¨ CPU: è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨ CPU

### é—®é¢˜ 3: æ•°æ®é›†ä¸‹è½½æ…¢

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä½¿ç”¨é•œåƒ (å¦‚æœåœ¨å›½å†…)
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†åˆ°ç¼“å­˜ç›®å½•
```

### é—®é¢˜ 4: Python è§£é‡Šå™¨æ‰¾ä¸åˆ°

**é”™è¯¯ä¿¡æ¯**:
```
é”™è¯¯: æ‰¾ä¸åˆ° Python è§£é‡Šå™¨ kvpress/.venv/bin/python
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
cd kvpress
UV_CACHE_DIR=$PWD/.cache/uv uv sync --all-groups
UV_CACHE_DIR=$PWD/.cache/uv uv sync --extra eval
cd ..
```

### é—®é¢˜ 5: PG19 ä¸‹è½½å¤±è´¥

**é”™è¯¯ä¿¡æ¯**:
```
Failed to download PG19 dataset
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ¸…ç†ç¼“å­˜é‡è¯•
rm -rf data/pg19/
./run_everything.sh
```

---

## ğŸ“ ç»“æœæ–‡ä»¶è¯´æ˜

### ç›®å½•ç»“æ„

```
results/
â”œâ”€â”€ streaming_llm/              # æˆ‘ä»¬çš„å®ç°ç»“æœ
â”‚   â”œâ”€â”€ wikitext_baseline.json
â”‚   â”œâ”€â”€ wikitext_result.json
â”‚   â”œâ”€â”€ pg19_baseline.json
â”‚   â”œâ”€â”€ pg19_result.json
â”‚   â”œâ”€â”€ ablation_window_size.json
â”‚   â””â”€â”€ ablation_n_sink.json
â”œâ”€â”€ kvpress/                    # kvpress å®˜æ–¹åº“ç»“æœ
â”‚   â”œâ”€â”€ wikitext_result.json
â”‚   â””â”€â”€ pg19_result.json
â”œâ”€â”€ figures/                    # å¯è§†åŒ–å›¾è¡¨
â”‚   â”œâ”€â”€ main_comparison.png
â”‚   â”œâ”€â”€ ablation_window_size.png
â”‚   â”œâ”€â”€ ablation_n_sink.png
â”‚   â”œâ”€â”€ results_summary.png
â”‚   â”œâ”€â”€ implementation_comparison.png
â”‚   â””â”€â”€ comparison_metrics_table.png
â”œâ”€â”€ decoding_latency_*.json     # Decoding latency ç»“æœ
â”œâ”€â”€ experiment_log_*.txt        # å®éªŒæ—¥å¿—
â””â”€â”€ experiment_summary_*.txt    # å®éªŒæ€»ç»“
```

### JSON æ–‡ä»¶æ ¼å¼

æ¯ä¸ª JSON ç»“æœæ–‡ä»¶åŒ…å«:

```json
{
  "model": "EleutherAI/pythia-70m",
  "dataset": "wikitext:wikitext-103-v1",
  "baseline": {
    "perplexity": 40.31,
    "runtime_sec": 0.401
  },
  "streaming": {
    "perplexity": 40.31,
    "runtime_sec": 0.032
  },
  "metrics": {
    "speedup": 12.4,
    "compression_ratio": 0.70,
    "ppl_increase_percent": 0.0
  }
}
```

---

## ğŸ“ˆ é¢„æœŸè¿è¡Œæ—¶é—´

åŸºäº NVIDIA GPU (å¦‚ RTX 3090):

| å®éªŒ | é¢„è®¡æ—¶é—´ |
|------|---------|
| WikiText-103 Baseline | ~2 åˆ†é’Ÿ |
| WikiText-103 StreamingLLM | ~1 åˆ†é’Ÿ |
| PG19 Baseline | ~1 åˆ†é’Ÿ |
| PG19 StreamingLLM | ~30 ç§’ |
| kvpress å¯¹æ¯”å®éªŒ | ~2 åˆ†é’Ÿ |
| Window Size æ¶ˆè | ~10 åˆ†é’Ÿ |
| N_sink æ¶ˆè | ~8 åˆ†é’Ÿ |
| å¯è§†åŒ–ç”Ÿæˆ | ~5 ç§’ |
| **æ€»è®¡** | **~25 åˆ†é’Ÿ** |

Decoding Latency å®éªŒ:

| å®éªŒ | é¢„è®¡æ—¶é—´ |
|------|---------|
| å•ä¸ªé…ç½® (3 runs) | ~3 åˆ†é’Ÿ |
| æ‰€æœ‰é…ç½® | ~20 åˆ†é’Ÿ |

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: æµ‹è¯•ä¸åŒçš„ window_size

```bash
# window_size = 512
python experiments/eval_streaming_llm.py \
  --window-size 512 \
  --output results/streaming_llm/window_512.json

# window_size = 2048
python experiments/eval_streaming_llm.py \
  --window-size 2048 \
  --output results/streaming_llm/window_2048.json
```

### ç¤ºä¾‹ 2: æµ‹è¯•ä¸åŒçš„ n_sink

```bash
# n_sink = 0 (æ—  sink)
python experiments/eval_streaming_llm.py \
  --n-sink 0 \
  --output results/streaming_llm/n_sink_0.json

# n_sink = 8
python experiments/eval_streaming_llm.py \
  --n-sink 8 \
  --output results/streaming_llm/n_sink_8.json
```

### ç¤ºä¾‹ 3: è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ

```bash
# è¿è¡Œ WikiText å¯¹æ¯”
python experiments/run_comparison.py --dataset wikitext

# è¿è¡Œ PG19 å¯¹æ¯”
python experiments/run_comparison.py --dataset pg19

# ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
python experiments/plot_comparison.py

# æŸ¥çœ‹ç»“æœ
ls results/streaming_llm/*_comparison.json
ls results/kvpress/*_comparison.json
ls results/figures/implementation_comparison.png
```

---

## ğŸ’¡ æç¤º

- é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹å’Œæ•°æ®é›†,éœ€è¦ä¸€äº›æ—¶é—´
- å»ºè®®å…ˆè¿è¡Œ `test_streaming_llm.py` ç¡®ä¿ç¯å¢ƒæ­£ç¡®
- ä½¿ç”¨ `--max-eval-tokens` æ§åˆ¶å®éªŒæ—¶é—´
- æ‰€æœ‰è„šæœ¬éƒ½æ”¯æŒ `--help` æŸ¥çœ‹å®Œæ•´å‚æ•°
- PG19 æ•°æ®é›†ä¼šæµå¼ä¸‹è½½ä¸€æ¡æ ·æœ¬å¹¶ä¿å­˜åˆ°æœ¬åœ° (`data/pg19/sample.json`)
- åç»­è¿è¡Œç›´æ¥ä½¿ç”¨æœ¬åœ°ç¼“å­˜,æ— éœ€é‡æ–°ä¸‹è½½

---

## ğŸ“ ä¸‹ä¸€æ­¥

1. âœ… è¿è¡Œå®éªŒå¹¶æ”¶é›†ç»“æœ
2. ğŸ“Š åˆ†æç»“æœæ•°æ®
3. ğŸ“ˆ æŸ¥çœ‹å¯è§†åŒ–å›¾è¡¨
4. ğŸ“„ é˜…è¯» README.md äº†è§£è¯¦ç»†ç»“æœ
5. ğŸ” æŸ¥çœ‹ DESIGN.md äº†è§£æŠ€æœ¯ç»†èŠ‚

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [README.md](README.md) - é¡¹ç›®æ€»è§ˆå’Œå®éªŒç»“æœ
- [DESIGN.md](DESIGN.md) - æŠ€æœ¯è®¾è®¡æ–‡æ¡£
- [EXPERIMENT_SCRIPTS_GUIDE.md](EXPERIMENT_SCRIPTS_GUIDE.md) - å®éªŒè„šæœ¬è¯¦ç»†è¯´æ˜
- [EXPERIMENT_VALIDATION_REPORT.md](EXPERIMENT_VALIDATION_REPORT.md) - å®éªŒéªŒè¯æŠ¥å‘Š

---

**CS3602 NLP å¤§ä½œä¸š**