{
  "model": "EleutherAI/pythia-2.8b",
  "dataset": "pg19:pg19",
  "split": "test",
  "max_length": 2048,
  "stride": 1022,
  "max_samples": 1,
  "max_eval_tokens": 20000,
  "total_tokens": 20000,
  "dataset_selector": {
    "PG19_SAMPLE_FILE": "data/pg19/long_context_50000.json",
    "PG19_SAMPLE_LENGTH": "50000",
    "WIKITEXT_SAMPLE_FILE": "data/wikitext/long_context_4096.json",
    "WIKITEXT_SAMPLE_LENGTH": "4096"
  },
  "streaming_llm": {
    "n_sink": 4,
    "window_size": 2044,
    "overlap": 0,
    "refresh_budget": 0,
    "refresh_policy": "none",
    "compress_every": 1,
    "max_drop": 0,
    "cache_slack": 0,
    "implementation": "ours",
    "cache_type": "StreamingKVCache",
    "max_cache_size": 2048
  },
  "baseline": {
    "perplexity": 19.761051177978516,
    "runtime_sec": 1758.043125,
    "prefill_sec": 0.4218440551757813,
    "first_token_latency_sec": 0.09493971252441406,
    "decode_tokens": 17952,
    "decode_time_sec": 1757.621280944824,
    "tpot_ms": 97.90671128257709,
    "peak_memory_mb": 5722.51171875
  },
  "baseline_source": "computed",
  "device": "cuda",
  "dtype": "torch.float16"
}