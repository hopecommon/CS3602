################################################################################
# StreamingLLM å®Œæ•´å®éªŒ
# å¼€å§‹æ—¶é—´: Thu Dec  4 05:03:30 PM CST 2025
################################################################################

[1;33m=== é˜¶æ®µ 1: Baseline å®éªŒ ===[0m

[0;34m========================================[0m
[0;34må®éªŒ 1: WikiText-103 Baseline[0m
[0;34m========================================[0m
å‘½ä»¤: kvpress/.venv/bin/python experiments/eval_streaming_llm.py         --dataset-name wikitext         --dataset-config wikitext-103-v1         --max-samples 64         --max-eval-tokens 4096         --n-sink 0         --window-size 999999         --output results/streaming_llm/wikitext_baseline.json
å¼€å§‹æ—¶é—´: Thu Dec  4 05:03:30 PM CST 2025
`torch_dtype` is deprecated! Use `dtype` instead!

============================================================
StreamingLLM è¯„ä¼°
============================================================
æ¨¡å‹: EleutherAI/pythia-70m
æ•°æ®é›†: wikitext:wikitext-103-v1
è®¾å¤‡: cuda
æ•°æ®ç±»å‹: torch.float16
n_sink: 0
window_size: 999999
============================================================

åŠ è½½ tokenizer...
åŠ è½½æ•°æ®é›†...
æ•°æ®é›†å¤§å°: 3407 tokens
åŠ è½½æ¨¡å‹...

============================================================
è¯„ä¼°åŸºçº¿ (æ— å‹ç¼©)
============================================================
åŸºçº¿ PPL: 40.31
åŸºçº¿ Runtime: 0.333s
åŸºçº¿ Prefill: 0.333s

============================================================
è¯„ä¼° StreamingLLM (æˆ‘ä»¬çš„å®ç°)
============================================================
StreamingLLM PPL: 40.31
StreamingLLM Runtime: 0.032s
StreamingLLM Prefill: 0.032s

============================================================
å®éªŒç»“æœ
============================================================
{
  "model": "EleutherAI/pythia-70m",
  "dataset": "wikitext:wikitext-103-v1",
  "split": "test",
  "max_length": 1024,
  "stride": 512,
  "max_samples": 64,
  "max_eval_tokens": 4096,
  "total_tokens": 3407,
  "streaming_llm": {
    "n_sink": 0,
    "window_size": 999999,
    "max_cache_size": 999999
  },
  "baseline": {
    "perplexity": 40.312744140625,
    "runtime_sec": 0.332583224051632,
    "prefill_sec": 0.3325814779382199
  },
  "streaming": {
    "perplexity": 40.312744140625,
    "runtime_sec": 0.031619644025340676,
    "prefill_sec": 0.03161905298475176
  },
  "metrics": {
    "speedup": 10.51824694120821,
    "compression_ratio": 0.0,
    "ppl_increase_percent": 0.0,
    "peak_memory_mb": 759.7294921875
  },
  "device": "cuda",
  "dtype": "torch.float16"
}
============================================================

ç»“æœå·²ä¿å­˜åˆ°: results/streaming_llm/wikitext_baseline.json

============================================================
æ€»ç»“
============================================================
åŠ é€Ÿæ¯”: 10.52x
å‹ç¼©æ¯”: 0.00%
PPL å¢åŠ : 0.00%
å³°å€¼æ˜¾å­˜: 759.7 MB
============================================================

[0;32mâœ“ æˆåŠŸ[0m (è€—æ—¶: 14s)


[0;34m========================================[0m
[0;34må®éªŒ 2: PG19 Baseline[0m
[0;34m========================================[0m
å‘½ä»¤: kvpress/.venv/bin/python experiments/eval_streaming_llm.py         --dataset-name pg19         --max-samples 1         --max-eval-tokens 4096         --n-sink 0         --window-size 999999         --output results/streaming_llm/pg19_baseline.json
å¼€å§‹æ—¶é—´: Thu Dec  4 05:03:44 PM CST 2025

============================================================
StreamingLLM è¯„ä¼°
============================================================
æ¨¡å‹: EleutherAI/pythia-70m
æ•°æ®é›†: pg19:wikitext-103-v1
è®¾å¤‡: cuda
æ•°æ®ç±»å‹: torch.float16
n_sink: 0
window_size: 999999
============================================================

åŠ è½½ tokenizer...
åŠ è½½æ•°æ®é›†...
æ£€æµ‹åˆ° PG19 æ•°æ®é›†...
æœ¬åœ°ç¼“å­˜ä¸å­˜åœ¨ï¼Œå¼€å§‹æµå¼ä¸‹è½½ PG19 æ•°æ®é›†...
æ³¨æ„: åªä¸‹è½½ä¸€æ¡æ ·æœ¬ä»¥èŠ‚çœç©ºé—´å’Œæ—¶é—´
Downloading builder script:   0%|          | 0.00/6.56k [00:00<?, ?B/s]Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.56k/6.56k [00:00<00:00, 10.7kB/s]Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.56k/6.56k [00:00<00:00, 10.7kB/s]
Downloading readme:   0%|          | 0.00/8.11k [00:00<?, ?B/s]Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.11k/8.11k [00:00<00:00, 12.5kB/s]Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.11k/8.11k [00:00<00:00, 12.5kB/s]
